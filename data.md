The EU AI Act: What You Need to Know

The following information is relevant for all IBM sales roles worldwide that collaborate with companies conducting business in the EU or with EU customers: The EU AI Act is the world's first comprehensive AI law and is scheduled to come into effect in stages during the second half of 2024. The law's focus on trust, security, and transparency will drive new levels of human oversight and regulatory compliance for AI within the EU. The law also has extraterritorial scope, meaning that AI developers and providers worldwide must prepare for the requirements of the EU AI Act. Companies will need to navigate a complex global regulatory landscape to successfully leverage generative AI. This presents a significant opportunity to position IBM's AI governance solutions (watsonx.governance) and drive IBM's growth in this area.

Key Points for Customer Discussions

The EU AI Act adopts a risk-based approach to compliance with relevant regulations. The law regulates not AI as a technology itself, but the use of AI based on its risk level: low, high, and unacceptable.

- For applications with low risk, it is unlikely that health, safety, and fundamental rights will be affected, hence these applications need to fulfill only a few transparency requirements.
- High-risk applications could potentially impact health or fundamental rights and must adhere to additional legal requirements. This includes applications used in critical areas such as transportation, education, security, employment, essential social services, police, migration, and justice, which may have potential impacts on citizens' lives, rights, and opportunities.
- Applications categorized as "unacceptable risk" are generally prohibited, with very few exceptions. This includes facial recognition, emotion recognition, or AI systems that exploit or influence people.
- General Purpose AI systems (GPAI), including generative AI and foundation models, are regulated under the law on two levels: systems with high impact and systems with low impact. Very stringent requirements apply to high-impact systems.
- Systems with high and low impact: Additional strict obligations apply to systems or models with high systemic risk.

The law provides a compliance deadline of up to three years. Prohibited systems have a shorter six-month compliance deadline. General purpose AI models have 12 months to meet transparency and governance requirements. Regulations for high-risk AI systems integrated as part of a product's safety component apply after 36 months. IBM is actively collaborating with policymakers to shape AI regulation

IBM has long supported an approach to usage-based regulation of AI. By collaborating with the European Union AI Commission's high-level expert group and the Organisation for Economic Co-operation and Development (OECD), which developed the standards on which the EU AI Act is based, IBM is able to assist customers in addressing this regulatory landscape change.

Integrated Governance Program (IGP)

IBM's Integrated Governance Program (IGP) enables the deployment of responsible AI for industrial customers. Our internal Integrated Governance Program, developed for the IBM Office of Privacy and Responsible Technology and based on IBM's principles-based governance framework and our own technology, helps efficiently manage more than 5,500 internal applications and processes, recently expanded to include AI governance.

Overview of watsonx.governance

Watsonx.governance supports the management and governance of both generative AI and traditional ML models throughout the AI lifecycle in an integrated platform. watsonx.governance provides risk management, model monitoring, assessment, and metadata capture/documentation using Factsheets to ensure transparent model processes and explainable outcomes. Collaborative tools, customizable dashboards, and reports enhance stakeholder communication and enterprise-wide visibility. Combining watsonx.governance with technical quality assurance helps companies proactively identify and mitigate risks, improving readiness to comply with the EU AI Act and other new AI regulations and industry standards.

Key Features of watsonx.governance

- Compliance - Supports AI transparency management and compliance with policies and standards. Connect data to key risk controls and use Factsheets to facilitate model metadata capture and reporting for inquiries and audits.
- Risk Management - Pre-set thresholds help proactively identify and mitigate AI model risks. Monitor fairness, drift, bias, performance compared to evaluation metrics, instances of toxic language, and personally identifiable information (PII). Gain insights into enterprise risk with user-based dashboards and reports.
- Lifecycle Governance and Monitoring - Supports management of generative AI and predictive machine learning models throughout their lifecycle using integrated workflows and approvals, monitoring the status of use cases, ongoing change requests, challenges, issues, and assigned tasks.

watsonx.governance and the EU AI Act

- Applicability and Risk Categorizations (Articles 5, 6 & 7)
- Questionnaire for assessing EU AI applicability and risk categorization (Management Console - MRG)
- Quality Management System (Article 17)
- Identification and assessment of AI risks (Article 9)
- Technical documentation and records (Articles 11, 12 & 18)
- Accuracy, robustness, and cyber monitoring (Article 15)
- Risk Atlas (Article 9)

Support from IBM Consulting

Given the rapid advancement of technologies and regulatory requirements, various aspects need consideration:

- Proper data management and AI governance must be established from the outset. IBM Consulting believes that AI governance is a societal and technological challenge that requires both organizational governance, processes, and training across the enterprise, as well as technical tools that enable them.
- IBM's strength in AI governance is unparalleled - it is a cornerstone of our culture and values. IBM Consulting has the industry and domain expertise to collaborate with customers in setting the right guardrails and ensuring responsible AI deployment across the organization. We work with our clients to develop a responsible, transparent AI strategy supported by organizational governance frameworks and automated AI governance platforms.
- The focus of the law is on trust, security, and transparency, leading to a new level of technical quality assurance and compliance with AI regulations in the EU. The law also has extraterritorial scope, meaning that AI developers and providers worldwide must be prepared to meet its requirements. IBM Consulting can help you navigate an increasingly complex global legal landscape to successfully leverage generative AI. We help establish the right organizational culture and governance structure and support you with the tools and AI engineering frameworks needed to ensure that your AI models behave as intended.

The IBM Office of Privacy and Responsible Technology as "Client Zero" for Privacy and AI Governance

The complex and ever-changing regulatory environment challenges companies to improve their compliance. IBM's approach to continuous compliance is supported by its Integrated Governance Program, addressing privacy and AI legal obligations across the enterprise. This growing portfolio of artifacts from the IBM Office of Privacy and Responsible Technology (formerly Chief Privacy Office) demonstrates the results of our cross-functional collaboration, innovation, and ongoing Integrated AI Governance journey, where IBM acts as "Client Zero".

Penalties

â‚¬35 million in potential fines for non-compliance with the EU AI Act, or 7% of a company's total worldwide annual revenue.

Trustworthy AI @ Scale

A holistic and phased approach to establishing scalable, sustainable organizational AI governance and AI model lifecycle governance. The approach consists of two central components: (a) Organizational AI Governance (strategy and planning) and (b) automated control and monitoring of the AI model lifecycle (development, deployment, operation, monitoring, and portfolio management).

Discussing the EU AI Act with Customers

- Gain an overview of current AI use cases within the customer organization.
- Assess the organization's maturity level regarding responsible AI and/or upcoming EU AI law requirements.
- Consult on activities from process, personnel, and technology perspectives.

Target Audience

- Chief Compliance Officer (CCO)
- Chief Risk Officer
- Privacy and AI Ethics Officer
- Chief Data Officer & Head of Data Science Department
- Chief Information Officer
- Operations Manager


